* [#A] Distance between vectors is off                         :twellik_demo:

1. find reliable place to check
2. compare results

*** cosine vs euclidean

while looking for test data, I came across this article:
[[https://cmry.github.io/notes/euclidean-v-cosine][Euclidean vs. Cosine Distance]]

it has some data but also an explanation about the topic. Or, at
least, about an interesting difference between cosine and Euclidean:

#+begin_quote
While cosine looks at the angle between vectors (thus not taking into
regard their weight or magnitude), euclidean distance is similar to
using a ruler to actually measure the distance. In our example the
angle between x14 and x4 was larger than those of the other vectors,
even though they were further away.
#+end_quote

*** clip to pinecone

maybe the way how I transform tensor to embeds is wrong?
this artical from pinecone should show how to transfrom model results
into vector db suitable vectors properly:

https://www.pinecone.io/learn/clip-image-search/

* TODO [#A] Hierarchical Navigable Small Worlds (HNSW)                 :core:

[[https://www.pinecone.io/learn/series/faiss/hnsw/][Pinecone: HNSW]]
[[https://arxiv.org/pdf/1603.09320.pdf][Efficient and robust approximate nearest neighbor search using
Hierarchical Navigable Small World graphs]]

[[https://github.com/jean-pierreBoth/hnswlib-rs/blob/master/tests/filtertest.rs][hnswlib-rs exmaple of filter]]

* [#A] Add support for distance formulas                               :core:

Curently, we have only poor implementation of cosine -- which might
not work properly even. There should be a way to define a distance
metric when defining index.

** DONE cosine
CLOSED: [2023-11-11 Sat 02:15]
cosine similarity vs. cosine distance:
dis = 1 - sim

** TODO dotproduct
** TODO euclid

* DONE [#A] Work in mem, serilize to store                             :core:
CLOSED: [2023-11-20 Mon 13:25]
or, rather, proper serialization strategy, -- at least so that each
query doesn't read whole db each time ðŸ˜„

** CANCELLED =Collection=: add_points method
CLOSED: [2023-11-20 Mon 13:08]

** DONE "db" object
CLOSED: [2023-11-20 Mon 13:08]

After I've spent some time with trying to fight with global mutex and
safe / borrowing rules of rust, it feels that it becomes more and more
cumbersome.

The reason is that I can't simply return a pointer to collection or
points, just because rust thinks that it is not safe. And it makes
sense.

So I was thinking, maybe it makes sense to revise the API so that all
the interact with DB by, first, opening db, returning an "object" and
then interacting with this db via this object.

Need to figure how to do it Rust / WASM

#+begin_src js
  let db = twellik.open("my-coll")
  // db.create_collection("my-coll")
  db.upsert_points("my-coll", points)
  let result = db.scroll_points("my-coll", { vector: [1, 2], k: 10, payload: { foo: 45}})
#+end_src

[[https://rustwasm.github.io/wasm-bindgen/contributing/design/exporting-rust-struct.html][wasm-bindgen guide: Exporting a struct to JS]]

*** Object stores in indexeddb can be only created in =onupgradeneeded=

from [[https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB#creating_and_structuring_the_store][Using IndexedDB: Creating and structuring the store]]:

#+begin_quote
As indicated previously, onupgradeneeded is the only place where you
can alter the structure of the database. In it, you can create and
delete object stores and build and remove indices.
#+end_quote

Another words, stores are sort of tables in traditional databases.
Therefore, I will probably stick to "db -> index binary" shape and
keep them all in one, global object store


** DONE treat "id" as unique key
CLOSED: [2023-11-20 Mon 13:25]


* DONE [#C] LocalStorage vs. IndexDB                                   :core:
CLOSED: [2023-11-18 Sat 14:30]

IndexDB has a binary storage, which might be an advantage. From the
other hand, it doesn't make sense to create overhead for db by using
another db.. storage should be simple and portable, this way it would
be easier to port Twellek from browser to WASI and other runtimes.

[[https://hacks.mozilla.org/2012/02/storing-images-and-files-in-indexeddb/][Mosilla Hacks: Storing images and files in IndexedDB]]

https://web.dev/articles/indexeddb-best-practices

=Blob= is not supported on Safari it seems:

#+begin_quote
Not everything can be stored in IndexedDB on all platforms

If you are storing large, user-generated files such as images or
videos, then you may try to store them as File or Blob objects. This
will work on some platforms but fail on others. Safari on iOS, in
particular, cannot store Blobs in IndexedDB.

Luckily it is not too difficult to convert a Blob into an ArrayBuffer,
and vice versa. Storing ArrayBuffers in IndexedDB is very well
supported.
#+end_quote

from [[https://developer.mozilla.org/en-US/docs/Web/API/IDBRequest][MDN: IDBRequest]] on =readyState=:
#+begin_quote
All asynchronous operations immediately return an IDBRequest
instance. Each request has a readyState that is set to the 'pending'
state; this changes to 'done' when the request is completed or
fails. When the state is set to done, every request returns a result
and an error, and an event is fired on the request. When the state is
still pending, any attempt to access the result or error raises an
InvalidStateError exception.
#+end_quote

** [?] How to pass-through data from e.g. indexdb by ref, to avoid copying?

*** DONE rkyv
CLOSED: [2023-11-17 Fri 01:03]

It could be not possible, however, we might at least avoid copying on
js<->rust format serialization using [[https://rkyv.org/][rkyv]] in combination with array
buffer / blob

*** DONE =AlignedVec= to =ArrayBuffer=, insert points
CLOSED: [2023-11-17 Fri 01:21]

** [?] What is [[https://docs.rs/js-sys/latest/js_sys/struct.SharedArrayBuffer.html][SharedArrayBuffer]]?

** [?] How to call js object methods from rust?
https://github.com/rustwasm/wasm-bindgen
[[https://rustwasm.github.io/docs/wasm-bindgen/][wasm-bindgen guide]]

import web-sys crate and activate feature flags
[[https://github.com/rustwasm/wasm-bindgen/blob/9fb3bca16876c756266274f78fcd0214e0581eaa/guide/src/web-sys/index.md?plain=1#L4][web-sys/index.md]]
https://rustwasm.github.io/wasm-bindgen/api/web_sys/struct.IdbRequest.html


** [?] using async in/from WASM
https://web.dev/articles/asyncify
https://rustwasm.github.io/wasm-bindgen/api/wasm_bindgen_futures/
[[https://users.rust-lang.org/t/can-you-turn-a-callback-into-a-future-into-async-await/49378/8][
how to impl future (turn cb into future)]]
[[https://www.reddit.com/r/rust/comments/bpmy21/what_is_the_rust_core_crate/][rust: core vs. std]]
[[https://rust-lang.github.io/async-book/02_execution/02_future.html][Async programming in Rust: The Future Trait]]

Why does passing a closure to function which accepts a function
pointer not work?

https://stackoverflow.com/questions/52696907/why-does-passing-a-closure-to-function-which-accepts-a-function-pointer-not-work


[[https://github.com/rustwasm/wasm-bindgen/issues/1126][#1126 Execute futures in WASM]]
... and here is exactly what I'm doing:
https://github.com/rustwasm/wasm-bindgen/issues/1126#issuecomment-451769937

... and here is a crate..!
https://github.com/Alorel/rust-indexed-db



* CANCELLED [?] Consider js/ts wrapper
CLOSED: [2023-11-20 Mon 16:08]
After I've spent some time with web_sys and indexed_db, I found it
pretty hard to make a wrappre for indexed db inside of WASM.

The idea was to convert indexed_db =open= to future which waits for
=readyState= of indexed_db -- to make it a little bit more elegant.

It seems I see the light in the end of this rabbit hole, however, it
feels too tricky for a simple db_open operation.

Mabe I should better make a small wrapper which opens db in JS and
passes it into WASM after? So that Rust assumes that it is ready and
successfully opened, to avoid all this hustle.
--
cancelling for now, using indexeddb futures crate

* [#C] WebGPU and vector instructions                                  :perf:

There's definitely a way to use webgpu in WASM, the question is how to
use GPU.

Second question is is there a way to use CPU vector extensions from
WASM, in browser in particular

**  vector instructions

*** what we can do with vector instructions, what types do we have :question:

SIMD

[!] hnsw_rs also has support for SIMD. However, I don't think it has
WASM simd support: but it might be handled via std/rustc?

[[https://gist.github.com/kbarbary/9efb3650f1b69b2b6b18e34ad347777b][Vector-matrix-vector multiplication with SIMD (AVX) intrinsics]]

https://www.cs.brandeis.edu/~cs146a/rust/rustbyexample-02-21-2015/simd.html
#+begin_src rust
fn simd_add_assign(xs: &mut Vec<f32>, ys: &Vec<f32>) {
    assert_equal_len!(xs, ys);

    let size = xs.len() as isize;
    let chunks = size / 4;

    // pointer to the start of the vector data
    let p_x: *mut f32 = xs.as_mut_ptr();
    let p_y: *const f32 = ys.as_ptr();

    // sum excess elements that don't fit in the simd vector
    for i in (4 * chunks)..size {
        // dereferencing a raw pointer requires an unsafe block
        unsafe {
            // offset by i elements
            *p_x.offset(i) += *p_y.offset(i);
        }
    }

    // treat f32 vector as an simd f32x4 vector
    let simd_p_x = p_x as *mut f32x4;
    let simd_p_y = p_y as *const f32x4;

    // sum "simd vector"
    for i in 0..chunks {
        unsafe {
            *simd_p_x.offset(i) += *simd_p_y.offset(i);
        }
    }
}
#+end_src

https://github.com/doxakis/CosineSimilarityComparison
#+begin_quote
There is a minimal cost to communicate with the GPU device (about 300
ms in the experimentation and only occur on the first GPU call). You
need to have a great amount of data to use the GPU. Otherwise, it's
slower than the single thread version. The communication cost with GPU
is negligible when using large arrays. If the array is too large, we
got an exception. (Maybe it's time to do batch processing and do
multiple GPU call.)

The Advanced Vector Extensions of modern CPU can be used per
thread. Adding more threads reduce the computation time. Compared to
the simple method, it uses about half (or less) the time to do the
same job in the integer version. If the dataset is a double array, the
performance is the same or worst.

Obviously, using double is way slower than integer. If possible,
always prefer integer. If you want to keep some digits, you could
multiple the number by 10 or 100 and convert it to integer. If you
really want to keep double, maybe you should consider using the GPU.

If we compare the vectorized version (integer array, v1 and v2), the
dot product is faster than doing an addition/multiplication on an
accumulator vector and taking the sum of the accumulator when having
small dimension in the array. (It's slower than the simple method on 1
thread.) But, if you consider an array with a lot of dimension, it's
faster using an accumulator vector than using the dot product
operation.
#+end_quote

[[https://www.sciencedirect.com/topics/computer-science/vector-instruction][Vector instructions]]
#+begin_quote
Vector instructions include instructions that perform floating-point
operations, instructions that load vector registers from memory and
store them to memory, instructions to manipulate vector mask
registers, and other special purpose instructions such as vector
shuffle.

From: Intel Xeon Phi Coprocessor High Performance Programming, 2013
#+end_quote

*** what types of vector instructions we have in browser available :question:

https://webassembly.github.io/spec/core/syntax/instructions.html#vector-instructions

https://doc.rust-lang.org/beta/core/arch/wasm32/index.html#simd

[[https://v8.dev/features/simd]]



** WebGPU
turns out, webgl can be used to search textures!
https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html

* [#C] Qdrant / Pinecone API                                     :adoptation:

In order to increase adoptability, there should be a way to easy move
your code and data from existing popular vector DBs.

** client / library interface
** guide how to move data from ... to twellik
** CSV import / export

* [#A] Unsplash search example                                         :demo:

** Host model for demo queries

* [#B] README, examples, pictures                                      :docs:
* [#C] ideas for demo
* [#A] Query language, simular to qdrant / elastic               :query_lang:
* [#C] SQL                                                       :query_lang:
* [#B] Quantization
* [#B] Hybrid search, vector + metadata
[[https://www.youtube.com/watch?v=taYoJ-mKLUI][YouTube: Natural Language Processing with Qdrant for Vector Similarity
Search]]

[[https://qdrant.tech/articles/hybrid-search/][On hybrid search (qdrant)]]
